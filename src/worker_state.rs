use std::collections::{BTreeMap, BTreeSet};
use std::path::PathBuf;
use std::sync::Arc;

use dbt_adapter::AdapterEngine;
use dbt_common::cancellation::CancellationTokenSource;
use dbt_common::io_args::IoArgs;
use dbt_jinja_utils::jinja_environment::JinjaEnv;
use dbt_schemas::materialization_resolver::MaterializationResolver;
use dbt_schemas::state::ResolverState;

use crate::types::{HooksConfig, RetryConfig};

/// Holds the parsed dbt project state, shared across all activities on a worker.
///
/// Initialized once at worker startup and stored in `ProjectRegistry`.
/// Activities access it via `self.registry.get(project_name)`.
pub struct WorkerState {
    /// The dbt project name (from dbt_project.yml).
    pub project_name: String,
    /// Resolved nodes, macros, dependencies.
    pub resolver_state: Arc<ResolverState>,
    /// Jinja environment configured for all phases.
    pub jinja_env: Arc<JinjaEnv>,
    /// Adapter engine for warehouse operations (default, from worker startup).
    pub adapter_engine: Arc<dyn AdapterEngine>,
    /// I/O args (project dir, output dir, invocation ID).
    pub io_args: IoArgs,
    /// Set of all package names in the project.
    pub packages: BTreeSet<String>,
    /// Default lifecycle hooks loaded from dbt_temporal.yml.
    pub default_hooks: HooksConfig,
    /// Default retry policy loaded from dbt_temporal.yml.
    pub default_retry: RetryConfig,
    /// Path to profiles.yml — needed for per-workflow adapter engine rebuilding.
    pub profiles_path: PathBuf,
    /// Profile name from dbt_project.yml (e.g. "waffle_hut").
    pub profile_name_in_project: String,
    /// Resolved default target name (e.g. "dev").
    pub default_target: String,
    /// Whether profiles.yml contains `env_var()` calls — gates per-workflow rebuilding.
    pub profile_uses_env_vars: bool,
    /// Compiled SQL per node, captured after resolve step.
    /// Keyed by common_attr.path (e.g. "models/stg_customers.sql").
    pub compiled_sql_cache: BTreeMap<String, String>,
    /// Snapshot raw SQL per node, captured after resolve step.
    pub snapshot_sql_cache: BTreeMap<String, String>,
    /// Test raw SQL per node (generated by resolver), captured before resolve output cleanup.
    /// Keyed by common_attr.path (e.g. "generic_tests/accepted_values_....sql").
    pub test_sql_cache: BTreeMap<String, String>,
    /// Resolves materialization macros with proper adapter inheritance and package precedence.
    pub materialization_resolver: Arc<MaterializationResolver>,
    /// Profile-level default schema at worker startup. Used to detect which nodes need
    /// schema patching when per-workflow env overrides change the profile schema.
    pub default_schema: String,
    /// Profile-level default database at worker startup.
    pub default_database: String,
    /// Whether the project overrides `generate_schema_name` (non-default naming may
    /// cause stale `this.schema` context variables with per-workflow env overrides).
    pub has_custom_schema_name_macro: bool,
    /// Keeps the CancellationTokenSource alive so the adapter engine's token
    /// isn't considered cancelled (the token uses a Weak ref to the source).
    #[allow(dead_code)]
    pub cancellation_source: CancellationTokenSource,
    /// Optional auth override for the adapter engine.
    /// When set, `rebuild_adapter_engine_with_env` uses this instead of the default auth.
    pub auth_override: Option<Arc<dyn dbt_auth::Auth>>,
}

impl std::fmt::Debug for WorkerState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("WorkerState")
            .field("project_name", &self.project_name)
            .field("packages", &self.packages)
            .field("profiles_path", &self.profiles_path)
            .field("default_target", &self.default_target)
            .finish_non_exhaustive()
    }
}
